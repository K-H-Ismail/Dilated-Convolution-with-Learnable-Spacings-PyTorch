{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor([[[[20.,  0., 40.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [60.,  0., 80.]]]], device='cuda:0',\n",
      "       grad_fn=<SurrogateDilationFullBackward>)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from termcolor import colored\n",
    "import torch\n",
    "\n",
    "from modules.Dcls2d import Dcls2d\n",
    "from modules.Dcls2dFull import Dcls2dFull\n",
    "\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "cuda_device = torch.device(\"cuda\")  # device object representing GPU\n",
    "\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "kernel_size = (2,2)\n",
    "dilation = (2,2)\n",
    "stride = (1,1)\n",
    "padding = (0,0)\n",
    "groups = 1\n",
    "bias = False\n",
    "\n",
    "m = torch.nn.Conv2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "n = Dcls2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "o = Dcls2dFull(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "X1 = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3., 4.],\n",
    "                                    [5., 6., 7., 8.], \n",
    "                                    [9., 10., 11., 12.],\n",
    "                                    [13., 14., 15., 16.]]]],device=cuda_device),\n",
    "                      requires_grad = True) \n",
    "X2 = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3., 4.],\n",
    "                                    [5., 6., 7., 8.], \n",
    "                                    [9., 10., 11., 12.],\n",
    "                                    [13., 14., 15., 16.]]]],device=cuda_device),\n",
    "                      requires_grad = True) \n",
    "X3 = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3., 4.],\n",
    "                                    [5., 6., 7., 8.], \n",
    "                                    [9., 10., 11., 12.],\n",
    "                                    [13., 14., 15., 16.]]]],device=cuda_device),\n",
    "                      requires_grad = True) \n",
    "m.weight = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[20., 40.],\n",
    "                                    [60., 80.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "n.weight = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[20., 40.],\n",
    "                                    [60., 80.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "o.weight = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[20., 40.],\n",
    "                                    [60., 80.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "\n",
    "height_out = (4 + 2 * padding[0] - (dilation[0] * (kernel_size[0] - 1) + 1)) / stride[0] + 1;\n",
    "print((dilation[0] * (kernel_size[0] - 1) + 1))\n",
    "width_out = (4 + 2 * padding[1] - (dilation[1] * (kernel_size[1] - 1) + 1)) / stride[1] + 1;\n",
    "back_truth = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2.],\n",
    "                                    [4., 5.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "\n",
    "var1 = (m(X1) - back_truth).norm()\n",
    "var2 = (n(X2) - back_truth).norm()\n",
    "var3 = (o(X3) - back_truth).norm()\n",
    "\n",
    "\n",
    "var1.backward();\n",
    "var2.backward();\n",
    "var3.backward();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 4])\n",
      "torch.Size([1, 1, 2, 2])\n",
      "torch.Size([1, 1, 2, 2])\n",
      "torch.Size([1, 1, 2, 2])\n",
      "torch.Size([1, 1, 2, 2])\n",
      "tensor([[[[1560., 1760.],\n",
      "          [2360., 2560.]]]], device='cuda:0',\n",
      "       grad_fn=<CudnnConvolutionBackward>)\n",
      "torch.Size([1, 1, 2, 2])\n",
      "tensor([[[[1560.4507, 1760.4507],\n",
      "          [2360.4507, 2560.4507]]]], device='cuda:0',\n",
      "       grad_fn=<SurrogateDilationBackward>)\n",
      "tensor([[[[20.,  0., 40.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [60.,  0., 80.]]]], device='cuda:0',\n",
      "       grad_fn=<SurrogateDilationFullBackward>)\n",
      "torch.Size([1, 1, 2, 2])\n",
      "tensor([[[[20.,  0., 40.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [60.,  0., 80.]]]], device='cuda:0',\n",
      "       grad_fn=<SurrogateDilationFullBackward>)\n",
      "tensor([[[[1560.4646, 1760.4646],\n",
      "          [2360.4646, 2560.4646]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[[[ 7.6718, 11.5944],\n",
      "          [23.3621, 27.2847]]]], device='cuda:0')\n",
      "tensor([[[[ 7.6717, 11.5943],\n",
      "          [23.3621, 27.2847]]]], device='cuda:0')\n",
      "tensor([[[[ 7.6717, 11.5943],\n",
      "          [23.3621, 27.2847]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(X1.size())\n",
    "print(m.weight.size())\n",
    "print(n.weight.size())\n",
    "print(o.weight.size())\n",
    "\n",
    "print(m(X1).size())\n",
    "print(m(X1))\n",
    "print(n(X2).size())\n",
    "print(n(X2))\n",
    "print(o(X2).size())\n",
    "print(o(X2))\n",
    "\n",
    "\n",
    "print(m.weight.grad) \n",
    "print(n.weight.grad)\n",
    "print(o.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1.],\n",
      "         [1., 1.]]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.]]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.]]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.]]], device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "R1 = torch.ceil(n.P1) - n.P1\n",
    "R2 = torch.ceil(n.P2) - n.P2\n",
    "\n",
    "print((1 - R1) * (1-R2))\n",
    "print((R1) * (1-R2))\n",
    "print((1 - R1) * (R2))\n",
    "print((R1) * (R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-2., -2.],\n",
      "          [ 0.,  0.]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(o.P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
