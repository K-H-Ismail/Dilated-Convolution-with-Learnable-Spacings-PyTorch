{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from termcolor import colored\n",
    "import torch\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "from modules.Dcls2d import Dcls2d\n",
    "from modules.Dcls2dFull import Dcls2dFull\n",
    "\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "cuda_device = torch.device(\"cuda\")  # device object representing GPU\n",
    "\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "kernel_size = (2,2)\n",
    "dilation = (2,2)\n",
    "stride = (1,1)\n",
    "padding = (0,0)\n",
    "groups = 1\n",
    "bias = False\n",
    "\n",
    "m = torch.nn.Conv2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "n = Dcls2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "o = Dcls2dFull(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "X1 = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3., 4.],\n",
    "                                    [5., 6., 7., 8.], \n",
    "                                    [9., 10., 11., 12.],\n",
    "                                    [13., 14., 15., 16.]]]],device=cuda_device),\n",
    "                      requires_grad = True) \n",
    "X2 = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3., 4.],\n",
    "                                    [5., 6., 7., 8.], \n",
    "                                    [9., 10., 11., 12.],\n",
    "                                    [13., 14., 15., 16.]]]],device=cuda_device),\n",
    "                      requires_grad = True) \n",
    "X3 = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3., 4.],\n",
    "                                    [5., 6., 7., 8.], \n",
    "                                    [9., 10., 11., 12.],\n",
    "                                    [13., 14., 15., 16.]]]],device=cuda_device),\n",
    "                      requires_grad = True) \n",
    "m.weight = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[20., 40.],\n",
    "                                    [60., 80.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "n.weight = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[20., 40.],\n",
    "                                    [60., 80.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "o.weight = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[20., 40.],\n",
    "                                    [60., 80.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "\n",
    "height_out = (4 + 2 * padding[0] - (dilation[0] * (kernel_size[0] - 1) + 1)) / stride[0] + 1;\n",
    "print((dilation[0] * (kernel_size[0] - 1) + 1))\n",
    "width_out = (4 + 2 * padding[1] - (dilation[1] * (kernel_size[1] - 1) + 1)) / stride[1] + 1;\n",
    "back_truth = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2.],\n",
    "                                    [4., 5.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True, profile_memory=True) as prof:\n",
    "    var2 = (n(X2) - back_truth).norm()\n",
    "var3 = (o(X3) - back_truth).norm()\n",
    "var1 = (m(X1) - back_truth).norm()\n",
    "\n",
    "var1.backward();\n",
    "var2.backward();\n",
    "var3.backward();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 4])\n",
      "torch.Size([1, 1, 2, 2])\n",
      "torch.Size([1, 1, 2, 2])\n",
      "torch.Size([1, 1, 2, 2])\n",
      "torch.Size([1, 1, 2, 2])\n",
      "tensor([[[[1560., 1760.],\n",
      "          [2360., 2560.]]]], device='cuda:0',\n",
      "       grad_fn=<CudnnConvolutionBackward>)\n",
      "torch.Size([1, 1, 2, 2])\n",
      "tensor([[[[1559.9611, 1759.9611],\n",
      "          [2359.9612, 2559.9612]]]], device='cuda:0',\n",
      "       grad_fn=<SurrogateDilationBackward>)\n",
      "torch.Size([1, 1, 2, 2])\n",
      "tensor([[[[1559.8484, 1759.8484],\n",
      "          [2359.8484, 2559.8484]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[[[ 7.6718, 11.5944],\n",
      "          [23.3621, 27.2847]]]], device='cuda:0')\n",
      "tensor([[[[ 7.6719, 11.5944],\n",
      "          [23.3621, 27.2847]]]], device='cuda:0')\n",
      "tensor([[[[ 7.6719, 11.5944],\n",
      "          [23.3621, 27.2847]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(X1.size())\n",
    "print(m.weight.size())\n",
    "print(n.weight.size())\n",
    "print(o.weight.size())\n",
    "\n",
    "print(m(X1).size())\n",
    "print(m(X1))\n",
    "print(n(X2).size())\n",
    "print(n(X2))\n",
    "print(o(X2).size())\n",
    "print(o(X2))\n",
    "\n",
    "\n",
    "print(m.weight.grad) \n",
    "print(n.weight.grad)\n",
    "print(o.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1.],\n",
      "         [1., 1.]]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.]]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.]]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.]]], device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "R1 = torch.ceil(n.P1) - n.P1\n",
    "R2 = torch.ceil(n.P2) - n.P2\n",
    "\n",
    "print((1 - R1) * (1-R2))\n",
    "print((R1) * (1-R2))\n",
    "print((1 - R1) * (R2))\n",
    "print((R1) * (R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-2., -2.],\n",
      "          [ 0.,  0.]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(o.P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   15872 B  |   27136 B  |  366080 B  |  350208 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   15872 B  |   27136 B  |  366080 B  |  350208 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    2048 KB |    2048 KB |    2048 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |    2032 KB |    2047 KB |    2389 KB |  365568 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |      31    |      53    |     704    |     673    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |      31    |      53    |     704    |     673    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       2    |       6    |     378    |     376    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=cuda_device, abbreviated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FunctionEventAvg' object has no attribute 'self_cuda_mem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e23749fcd922>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_averages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msort_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"self_cuda_mem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36mtable\u001b[0;34m(self, sort_by, row_limit, header, top_level_events_only)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \"\"\"\n\u001b[0;32m--> 172\u001b[0;31m         return build_table(\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0msort_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_by\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36mbuild_table\u001b[0;34m(events, sort_by, header, row_limit, use_cuda, profile_memory, top_level_events_only)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msort_by\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         events = EventList(sorted(\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_by\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         ), use_cuda=use_cuda, profile_memory=profile_memory)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(evt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msort_by\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m         events = EventList(sorted(\n\u001b[0;32m-> 1177\u001b[0;31m             \u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_by\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m         ), use_cuda=use_cuda, profile_memory=profile_memory)\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FunctionEventAvg' object has no attribute 'self_cuda_mem'"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"self_cuda_mem\", row_limit=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
    "                    Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
    "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
    "       SurrogateDilation         7.18%     348.164us        96.64%       4.685ms       4.685ms       2.399ms        48.21%       4.945ms       4.945ms           0 b           0 b         512 b     -10.00 Kb             1  \n",
    "             aten::addmm        73.38%       3.557ms        73.56%       3.566ms       3.566ms       2.335ms        46.92%       2.335ms       2.335ms           0 b           0 b         512 b           0 b             1  \n",
    "             aten::clamp         2.22%     107.562us         4.04%     195.795us      24.474us      42.400us         0.85%      60.704us       7.588us           0 b           0 b       4.00 Kb           0 b             8  \n",
    "               aten::sub         2.74%     132.760us         3.38%     163.643us      23.378us      52.320us         1.05%      52.320us       7.474us           0 b           0 b       3.50 Kb           0 b             7  \n",
    "             aten::floor         2.52%     121.967us         5.08%     246.098us      61.524us      24.160us         0.49%      35.232us       8.808us           0 b           0 b       2.00 Kb           0 b             4  \n",
    "            aten::select         1.63%      78.892us         1.76%      85.474us      12.211us      28.672us         0.58%      28.672us       4.096us           0 b           0 b           0 b           0 b             7  \n",
    "               aten::mul         1.46%      70.946us         1.79%      86.690us      21.673us      26.784us         0.54%      26.784us       6.696us           0 b           0 b       2.00 Kb           0 b             4  \n",
    "    aten::frobenius_norm         0.54%      26.065us         2.62%     126.994us     126.994us       5.856us         0.12%      24.928us      24.928us           0 b           0 b       1.00 Kb           0 b             1  \n",
    "             aten::copy_         1.61%      78.109us         1.61%      78.109us      26.036us      21.567us         0.43%      21.567us       7.189us           0 b           0 b           0 b           0 b             3  \n",
    "              aten::add_         1.16%      56.354us         1.16%      56.354us      28.177us      19.200us         0.39%      19.200us       9.600us           0 b           0 b           0 b           0 b             2  \n",
    "              aten::norm         1.22%      59.353us         1.39%      67.418us      67.418us      10.880us         0.22%      10.880us      10.880us           0 b           0 b         512 b           0 b             1  \n",
    "         aten::ones_like         0.25%      11.891us         1.00%      48.387us      48.387us       4.256us         0.09%      10.240us      10.240us           0 b           0 b         512 b           0 b             1  \n",
    "             aten::fill_         0.51%      24.793us         0.51%      24.793us      24.793us       5.984us         0.12%       5.984us       5.984us           0 b           0 b           0 b           0 b             1  \n",
    "             aten::empty         1.71%      82.755us         1.71%      82.755us       3.598us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       7.50 Kb       7.50 Kb            23  \n",
    "           aten::resize_         0.96%      46.379us         0.96%      46.379us       5.797us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       4.00 Kb       4.00 Kb             8  \n",
    "        aten::empty_like         0.09%       4.601us         0.24%      11.703us      11.703us       0.000us         0.00%       0.000us       0.000us           0 b           0 b         512 b           0 b             1  \n",
    "     aten::empty_strided         0.15%       7.102us         0.15%       7.102us       7.102us       0.000us         0.00%       0.000us       0.000us           0 b           0 b         512 b         512 b             1  \n",
    "              aten::view         0.44%      21.254us         0.44%      21.254us       3.036us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             7  \n",
    "        aten::as_strided         0.18%       8.892us         0.18%       8.892us       0.988us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             9  \n",
    "            aten::expand         0.03%       1.558us         0.05%       2.351us       2.351us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
    "            aten::stride         0.02%       1.079us         0.02%       1.079us       0.360us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
    "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
    "Self CPU time total: 4.848ms\n",
    "CUDA time total: 4.976ms\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
