{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from termcolor import colored\n",
    "import torch\n",
    "\n",
    "from modules.Dcls2d import Dcls2d\n",
    "from modules.Dcls2d_old import Dcls2d_old\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "cuda_device = torch.device(\"cuda\")  # device object representing GPU\n",
    "\n",
    "in_channels = 2\n",
    "out_channels = 2\n",
    "kernel_size = (3,3)\n",
    "dilation = (1,1)\n",
    "stride = (1,1)\n",
    "padding = (0,0)\n",
    "groups = 2\n",
    "bias = False\n",
    "\n",
    "m = torch.nn.Conv2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "n = Dcls2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "X1 = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3., 4., 5.],\n",
    "                                    [6., 7., 8., 9., 10.], \n",
    "                                    [11., 12., 13., 14., 15.],\n",
    "                                    [16., 17., 18., 19., 20.],                                   \n",
    "                                    [21., 22., 23., 24., 25.]],\n",
    "                                    [[-1., -2., -3., -4., -5.],\n",
    "                                    [-6., -7., -8., -9., -10.], \n",
    "                                    [-11., -12., -13., -14., -15.],\n",
    "                                    [-16., -17., -18., -19., -20.],                                   \n",
    "                                    [-21., -22., -23., -24., -25.]]]],device=cuda_device),\n",
    "                      requires_grad = True) \n",
    "X2 = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3., 4., 5.],\n",
    "                                    [6., 7., 8., 9., 10.], \n",
    "                                    [11., 12., 13., 14., 15.],\n",
    "                                    [16., 17., 18., 19., 20.],                                   \n",
    "                                    [21., 22., 23., 24., 25.]],\n",
    "                                    [[-1., -2., -3., -4., -5.],\n",
    "                                    [-6., -7., -8., -9., -10.], \n",
    "                                    [-11., -12., -13., -14., -15.],\n",
    "                                    [-16., -17., -18., -19., -20.],                                   \n",
    "                                    [-21., -22., -23., -24., -25.]]]],device=cuda_device),\n",
    "                      requires_grad = True) \n",
    "n.weight = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3.],\n",
    "                                    [4., 5., 6.], \n",
    "                                    [7., 8., 9.]]],\n",
    "                                    [[[10., 20., 30.],\n",
    "                                    [40., 50., 60.], \n",
    "                                    [70., 80., 90.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "m.weight = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3.],\n",
    "                                    [4., 5., 6.], \n",
    "                                    [7., 8., 9.]]],\n",
    "                                    [[[10., 20., 30.],\n",
    "                                    [40., 50., 60.], \n",
    "                                    [70., 80., 90.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "\n",
    "height_out = (5 + 2 * padding[0] - (dilation[0] * (kernel_size[0] - 1) + 1)) / stride[0] + 1;\n",
    "width_out = (5 + 2 * padding[1] - (dilation[1] * (kernel_size[1] - 1) + 1)) / stride[1] + 1;\n",
    "back_truth = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3.],\n",
    "                                    [4., 5., 6.], \n",
    "                                    [7., 8., 9.]]],\n",
    "                                    [[[1., 2., 3.],\n",
    "                                    [4., 5., 6.], \n",
    "                                    [7., 8., 9.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "\n",
    "var1 = (m(X1) - back_truth).norm()\n",
    "var2 = (n(X2) - back_truth).norm()\n",
    "#var3 = (o(Y) - backtruth).norm()\n",
    "var1.backward();\n",
    "var2.backward();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 5, 5])\n",
      "torch.Size([2, 1, 3, 3])\n",
      "torch.Size([2, 1, 3, 3])\n",
      "tensor([[[[ 3.2859,  3.6897,  4.0934],\n",
      "          [ 5.3047,  5.7085,  6.1123],\n",
      "          [ 7.3236,  7.7273,  8.1311]]],\n",
      "\n",
      "\n",
      "        [[[33.1589, 37.2294, 41.2999],\n",
      "          [53.5115, 57.5820, 61.6525],\n",
      "          [73.8641, 77.9346, 82.0051]]]], device='cuda:0')\n",
      "tensor([[[[ 3.2850,  3.6887,  4.0923],\n",
      "          [ 5.3033,  5.7069,  6.1105],\n",
      "          [ 7.3215,  7.7251,  8.1288]]],\n",
      "\n",
      "\n",
      "        [[[33.1590, 37.2295, 41.3001],\n",
      "          [53.5117, 57.5822, 61.6527],\n",
      "          [73.8643, 77.9348, 82.0054]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(X1.size())\n",
    "print(m.weight.size())\n",
    "print(n.weight.size())\n",
    "\n",
    "'''print(m(X1).size())\n",
    "print(m(X1))\n",
    "print(n(X2).size())\n",
    "print(n(X2))'''\n",
    "\n",
    "print(m.weight.grad) \n",
    "print(n.weight.grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elementary_test(test_name = \"test_elem\", print_tensors = False,\n",
    "                    random_weights = True , batch = 1,\n",
    "                    in_channels = 1, out_channels = 1, \n",
    "                    stride = (1,1), padding = (0,0), \n",
    "                    dilation = (1,1), kernel_size = (3,3), \n",
    "                    img_size = (8,7), bias = None, \n",
    "                    groups = 1):\n",
    "    \n",
    "    print(\"\\n\"+ test_name + \"\\n--------------------------\")\n",
    "\n",
    "    m = torch.nn.Conv2d(in_channels=in_channels,\n",
    "                  out_channels=out_channels,\n",
    "                  kernel_size=kernel_size,\n",
    "                  dilation=dilation,\n",
    "                  stride=stride,\n",
    "                  padding=padding,\n",
    "                  groups=groups,\n",
    "                  bias=bias).to(cuda_device)\n",
    "\n",
    "    n = Dcls2d(in_channels=in_channels,\n",
    "                  out_channels=out_channels,\n",
    "                  kernel_size=kernel_size,\n",
    "                  dilation=dilation,\n",
    "                  stride=stride,\n",
    "                  padding=padding,\n",
    "                  groups=groups,\n",
    "                  bias=bias).to(cuda_device)\n",
    "\n",
    "    o = Dcls2d_old(in_channels=in_channels,\n",
    "                  out_channels=out_channels,\n",
    "                  kernel_size=kernel_size,\n",
    "                  dilation=dilation,\n",
    "                  stride=stride,\n",
    "                  padding=padding,\n",
    "                  groups=groups,\n",
    "                  bias=bias).to(cuda_device)\n",
    "\n",
    "    Y1 = torch.nn.Parameter(torch.randn((batch,in_channels,*img_size),device=cuda_device), requires_grad = True)\n",
    "    Y2 = torch.nn.Parameter(torch.randn((batch,in_channels,*img_size),device=cuda_device), requires_grad = True)\n",
    "    Y3 = torch.nn.Parameter(torch.randn((batch,in_channels,*img_size),device=cuda_device), requires_grad = True)    \n",
    "    Y3.data = Y2.data = Y1.data\n",
    "    W = torch.nn.Parameter(torch.randn((out_channels,in_channels//groups,*kernel_size),device=cuda_device), requires_grad = True)\n",
    "    B = torch.nn.Parameter(torch.randn((out_channels),device=cuda_device), requires_grad = True)\n",
    "    #o.weight = torch.nn.Parameter(torch.randn((out_channels,in_channels//groups,*kernel_size),device=cuda_device), requires_grad = True)\n",
    "    n.weight = torch.nn.Parameter(torch.randn((out_channels,in_channels//groups,*kernel_size),device=cuda_device), requires_grad = True)\n",
    "    m.weight = torch.nn.Parameter(torch.randn((out_channels,in_channels//groups,*kernel_size),device=cuda_device), requires_grad = True)\n",
    "    m.bias = torch.nn.Parameter(torch.randn((out_channels),device=cuda_device))\n",
    "    n.bias = torch.nn.Parameter(torch.randn((out_channels),device=cuda_device))\n",
    "    #o.bias = torch.nn.Parameter(torch.randn((out_channels),device=cuda_device))\n",
    "\n",
    "    \n",
    "    m.weight.data = W.data\n",
    "    n.weight.data = W.data\n",
    "    #o.weight.data = W.data\n",
    "    \n",
    "    \n",
    "    m.bias.data = B.data\n",
    "    n.bias.data = B.data\n",
    "    #o.bias.data = B.data\n",
    "    \n",
    "    height_out = (img_size[0] + 2 * padding[0] - (dilation[0] * (kernel_size[0] - 1) + 1)) / stride[0] + 1;\n",
    "    width_out = (img_size[1] + 2 * padding[1] - (dilation[1] * (kernel_size[1] - 1) + 1)) / stride[1] + 1;\n",
    "    back_truth = torch.randn((batch,out_channels,int(height_out),int(width_out)),device=cuda_device)\n",
    "    \n",
    "\n",
    "    print(\"#Forward check\")\n",
    "    \n",
    "    if (print_tensors):\n",
    "        print(m(Y1))\n",
    "        print(n(Y2))\n",
    "\n",
    "    print(colored('True', 'green')) if torch.all(torch.abs(m(Y1) - n(Y2))/torch.abs(m(Y1)) < 1e-1) else print(colored('False', 'red'))\n",
    "    #print(colored('True', 'green')) if torch.all(torch.abs(m(Y1) - o(Y3)) < 1e-2) else print(colored('False', 'red'))\n",
    "   \n",
    "    print(\"#Backward check\")\n",
    "\n",
    "    var1 = (m(Y1) - back_truth).norm()\n",
    "    var2 = (n(Y2) - back_truth).norm()\n",
    "    #var3 = (o(Y) - backtruth).norm()\n",
    "    var1.backward();\n",
    "    var2.backward();\n",
    "    #var3.backward();\n",
    "\n",
    "    if (print_tensors):\n",
    "        print(m.weight.grad)\n",
    "        print(n.weight.grad)\n",
    "        #print(o.weight)\n",
    "\n",
    "    print(colored('True', 'green')) if torch.all(torch.abs(m.weight.grad - n.weight.grad)/torch.abs(m.weight.grad) < 1e-1) else print(colored('False', 'red'))\n",
    "    print(colored('True', 'green')) if torch.all(torch.abs(Y1.grad - Y2.grad)/torch.abs(Y1.grad) < 1e-2) else print(colored('False', 'red')    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test_dil\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_dil\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_dil\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_dil\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_batch\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_ch_in\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_ch_out\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_batch_ch_in_out\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_kernel_size\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_img_size\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_padding\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_stride\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_all\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_dilation\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_all_dilation\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_groups\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_all_groups\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "elementary_test(\"test_dil\", dilation = (6,5), kernel_size = (3,3), img_size=(32,20))\n",
    "elementary_test(\"test_dil\", dilation = (5,6), kernel_size = (3,3), img_size=(40,50))\n",
    "elementary_test(\"test_dil\", dilation = (6,6), kernel_size = (3,3), img_size=(49,56))\n",
    "elementary_test(\"test_dil\", dilation = (5,5), kernel_size = (3,3), img_size=(120,57))\n",
    "\n",
    "elementary_test(\"test_batch\", batch = 42)\n",
    "elementary_test(\"test_ch_in\", in_channels = 64, img_size = (100,100))\n",
    "elementary_test(\"test_ch_out\", out_channels = 128, print_tensors = False)\n",
    "elementary_test(\"test_batch_ch_in_out\", batch = 42, in_channels = 64,  out_channels = 32)\n",
    "\n",
    "elementary_test(\"test_kernel_size\", kernel_size = (4,3))\n",
    "elementary_test(\"test_img_size\", img_size = (233,239))\n",
    "elementary_test(\"test_padding\", padding = (33,22))\n",
    "elementary_test(\"test_stride\", stride = (2,3))\n",
    "elementary_test(\"test_all\", batch = 10, in_channels = 32, out_channels = 16, kernel_size = (4,3), \n",
    "               img_size = (32,37), padding = (33,22), stride = (2,3))\n",
    "\n",
    "elementary_test(\"test_dilation\", dilation = (3,2))\n",
    "elementary_test(\"test_all_dilation\", batch = 42, in_channels = 32, out_channels = 16, kernel_size = (4,3), \n",
    "                img_size = (233,239), padding = (33,22), stride = (2,3), dilation = (3,2))\n",
    "\n",
    "elementary_test(\"test_groups\", in_channels = 64, out_channels = 64, groups = 64)\n",
    "elementary_test(\"test_all_groups\", batch = 10, in_channels = 32, out_channels = 32, kernel_size = (4,3), \n",
    "                img_size = (32,37), padding = (33,22), stride = (2,3), dilation = (3,2), groups = 32)\n",
    "#elementary_test(\"test_bias\", batch = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 16\n",
    "in_channels = 128\n",
    "out_channels = 256\n",
    "stride = (1,1)\n",
    "padding = (0,0)\n",
    "dilation = (4,3)\n",
    "kernel_size = (4,3)\n",
    "img_size = (108,64)\n",
    "bias = False\n",
    "groups = 1\n",
    "    \n",
    "elementary_test(\"test_snnap\", batch = 64, in_channels = 64, out_channels = 64, kernel_size = (4,3), \n",
    "                img_size = (108,64), padding = (0,0), stride = (1,1), dilation = (4,3))\n",
    "\n",
    "m = torch.nn.Conv2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "n = Dcls2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "o = Dcls2d_old(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "Y = torch.nn.Parameter(torch.randn((batch,in_channels,*img_size),device=cuda_device))\n",
    "o.weight = n.weight = m.weight = torch.nn.Parameter(torch.ones((out_channels,in_channels//groups,*kernel_size),device=cuda_device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward = 0\n",
    "backward = 0\n",
    "for _ in range(10):\n",
    "    start = time.time()\n",
    "    a = m(Y)\n",
    "    torch.cuda.synchronize()\n",
    "    forward += time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    (a.sum()).backward()\n",
    "    torch.cuda.synchronize()\n",
    "    backward += time.time() - start\n",
    "\n",
    "print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e1, backward * 1e6/1e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward = 0\n",
    "backward = 0\n",
    "for _ in range(10):\n",
    "    start = time.time()\n",
    "    b = n(Y)\n",
    "    torch.cuda.synchronize()\n",
    "    forward += time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    (b.sum() ).backward()\n",
    "    torch.cuda.synchronize()\n",
    "    backward += time.time() - start\n",
    "\n",
    "print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e1, backward * 1e6/1e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6150001faa64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbackward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "forward = 0\n",
    "backward = 0\n",
    "for _ in range(10):\n",
    "    start = time.time()\n",
    "    c = o(Y)\n",
    "    torch.cuda.synchronize()\n",
    "    forward += time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    (c.sum() ).backward()\n",
    "    torch.cuda.synchronize()\n",
    "    backward += time.time() - start\n",
    "\n",
    "print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e1, backward * 1e6/1e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
