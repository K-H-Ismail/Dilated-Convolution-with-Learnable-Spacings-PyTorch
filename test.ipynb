{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from termcolor import colored\n",
    "import torch\n",
    "\n",
    "from modules.Dcls2d import Dcls2d\n",
    "from modules.Dcls2d_old import Dcls2d_old\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "cuda_device = torch.device(\"cuda\")  # device object representing GPU\n",
    "\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "kernel_size = (3,3)\n",
    "dilation = (1,1)\n",
    "stride = (1,1)\n",
    "padding = (0,0)\n",
    "groups = 1\n",
    "bias = False\n",
    "\n",
    "m = torch.nn.Conv2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "n = Dcls2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "X = torch.nn.Parameter(\n",
    "                      torch.tensor([[1., 2., 3., 4., 5.],\n",
    "                                    [6., 7., 8., 9., 10.], \n",
    "                                    [11., 12., 13., 14., 15.],\n",
    "                                    [16., 17., 18., 19., 20.],                                   \n",
    "                                    [21., 22., 23., 24., 25.],],device=cuda_device).unsqueeze(0).unsqueeze(0),\n",
    "                      requires_grad = True) \n",
    "n.weight = m.weight = torch.nn.Parameter(\n",
    "                      torch.tensor([[1., 2., 3.],\n",
    "                                    [4., 5., 6.], \n",
    "                                    [7., 8., 9.], ],device=cuda_device).unsqueeze(0).unsqueeze(0),\n",
    "                      requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 5, 5])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "tensor([[[[411., 456., 501.],\n",
      "          [636., 681., 726.],\n",
      "          [861., 906., 951.]]]], device='cuda:0',\n",
      "       grad_fn=<CudnnConvolutionBackward>)\n",
      "torch.Size([1, 1, 3, 3])\n",
      "tensor([[[[410.7680, 455.7680, 500.7680],\n",
      "          [635.7680, 680.7680, 725.7680],\n",
      "          [860.7680, 905.7680, 950.7680]]]], device='cuda:0',\n",
      "       grad_fn=<SurrogateDilationBackward>)\n",
      "Parameter containing:\n",
      "tensor([[[[-1., -1., -1.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 1.,  1.,  1.]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(X.size())\n",
    "print(m.weight.size())\n",
    "print(n.weight.size())\n",
    "\n",
    "print(m(X).size())\n",
    "print(m(X))\n",
    "print(n(X).size())\n",
    "print(n(X))\n",
    "\n",
    "print(n.P1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elementary_test(test_name = \"test_elem\", print_tensors = False,\n",
    "                    random_weights = True , batch = 1,\n",
    "                    in_channels = 1, out_channels = 1, \n",
    "                    stride = (1,1), padding = (0,0), \n",
    "                    dilation = (1,1), kernel_size = (3,3), \n",
    "                    img_size = (8,7), bias = None, \n",
    "                    groups = 1):\n",
    "    \n",
    "    print(\"\\n\"+ test_name + \"\\n--------------------------\")\n",
    "\n",
    "    m = torch.nn.Conv2d(in_channels=in_channels,\n",
    "                  out_channels=out_channels,\n",
    "                  kernel_size=kernel_size,\n",
    "                  dilation=dilation,\n",
    "                  stride=stride,\n",
    "                  padding=padding,\n",
    "                  groups=groups,\n",
    "                  bias=bias).to(cuda_device)\n",
    "\n",
    "    n = Dcls2d(in_channels=in_channels,\n",
    "                  out_channels=out_channels,\n",
    "                  kernel_size=kernel_size,\n",
    "                  dilation=dilation,\n",
    "                  stride=stride,\n",
    "                  padding=padding,\n",
    "                  groups=groups,\n",
    "                  bias=bias).to(cuda_device)\n",
    "\n",
    "    o = Dcls2d_old(in_channels=in_channels,\n",
    "                  out_channels=out_channels,\n",
    "                  kernel_size=kernel_size,\n",
    "                  dilation=dilation,\n",
    "                  stride=stride,\n",
    "                  padding=padding,\n",
    "                  groups=groups,\n",
    "                  bias=bias).to(cuda_device)\n",
    "\n",
    "    Y1 = torch.nn.Parameter(torch.randn((batch,in_channels,*img_size),device=cuda_device), requires_grad = True)\n",
    "    Y2 = torch.nn.Parameter(torch.randn((batch,in_channels,*img_size),device=cuda_device), requires_grad = True)\n",
    "    Y3 = torch.nn.Parameter(torch.randn((batch,in_channels,*img_size),device=cuda_device), requires_grad = True)    \n",
    "    Y3.data = Y2.data = Y1.data\n",
    "    W = torch.nn.Parameter(torch.randn((out_channels,in_channels//groups,*kernel_size),device=cuda_device), requires_grad = True)\n",
    "    B = torch.nn.Parameter(torch.randn((out_channels),device=cuda_device), requires_grad = True)\n",
    "    #o.weight = torch.nn.Parameter(torch.randn((out_channels,in_channels//groups,*kernel_size),device=cuda_device), requires_grad = True)\n",
    "    n.weight = torch.nn.Parameter(torch.randn((out_channels,in_channels//groups,*kernel_size),device=cuda_device), requires_grad = True)\n",
    "    m.weight = torch.nn.Parameter(torch.randn((out_channels,in_channels//groups,*kernel_size),device=cuda_device), requires_grad = True)\n",
    "    m.bias = torch.nn.Parameter(torch.randn((out_channels),device=cuda_device))\n",
    "    n.bias = torch.nn.Parameter(torch.randn((out_channels),device=cuda_device))\n",
    "    #o.bias = torch.nn.Parameter(torch.randn((out_channels),device=cuda_device))\n",
    "\n",
    "    \n",
    "    m.weight.data = W.data\n",
    "    n.weight.data = W.data\n",
    "    #o.weight.data = W.data\n",
    "    \n",
    "    \n",
    "    m.bias.data = B.data\n",
    "    n.bias.data = B.data\n",
    "    #o.bias.data = B.data\n",
    "    \n",
    "    height_out = (img_size[0] + 2 * padding[0] - (dilation[0] * (kernel_size[0] - 1) + 1)) / stride[0] + 1;\n",
    "    width_out = (img_size[1] + 2 * padding[1] - (dilation[1] * (kernel_size[1] - 1) + 1)) / stride[1] + 1;\n",
    "    back_truth = torch.randn((batch,out_channels,int(height_out),int(width_out)),device=cuda_device)\n",
    "    \n",
    "\n",
    "    print(\"#Forward check\")\n",
    "    \n",
    "    if (print_tensors):\n",
    "        print(m(Y1))\n",
    "        print(n(Y2))\n",
    "\n",
    "    print(colored('True', 'green')) if torch.all(torch.abs(m(Y1) - n(Y2))/torch.abs(m(Y1)) < 1e-2) else print(colored('False', 'red'))\n",
    "    #print(colored('True', 'green')) if torch.all(torch.abs(m(Y1) - o(Y3)) < 1e-2) else print(colored('False', 'red'))\n",
    "   \n",
    "    print(\"#Backward check\")\n",
    "\n",
    "    var1 = (m(Y1) - back_truth).norm()\n",
    "    var2 = (n(Y2) - back_truth).norm()\n",
    "    #var3 = (o(Y) - backtruth).norm()\n",
    "    var1.backward();\n",
    "    var2.backward();\n",
    "    #var3.backward();\n",
    "\n",
    "    if (print_tensors):\n",
    "        print(m.weight.grad)\n",
    "        print(n.weight.grad)\n",
    "        #print(o.weight)\n",
    "\n",
    "    print(colored('True', 'green')) if torch.all(torch.abs(m.weight.grad - n.weight.grad)/torch.abs(m.weight.grad) < 1e-2) else print(colored('False', 'red'))\n",
    "    print(colored('True', 'green')) if torch.all(torch.abs(Y1.grad - Y2.grad)/torch.abs(Y1.grad) < 1e-2) else print(colored('False', 'red')    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test_dil\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_dil\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_dil\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_dil\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_batch\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_ch_in\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_ch_out\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_batch_ch_in_out\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_kernel_size\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_img_size\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_padding\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_stride\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_all\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_dilation\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_all_dilation\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_groups\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_all_groups\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "elementary_test(\"test_dil\", dilation = (6,5), kernel_size = (3,3), img_size=(32,20))\n",
    "elementary_test(\"test_dil\", dilation = (5,6), kernel_size = (3,3), img_size=(40,50))\n",
    "elementary_test(\"test_dil\", dilation = (6,6), kernel_size = (3,3), img_size=(49,56))\n",
    "elementary_test(\"test_dil\", dilation = (5,5), kernel_size = (3,3), img_size=(120,57))\n",
    "\n",
    "elementary_test(\"test_batch\", batch = 42)\n",
    "elementary_test(\"test_ch_in\", in_channels = 64, img_size = (100,100))\n",
    "elementary_test(\"test_ch_out\", out_channels = 128, print_tensors = False)\n",
    "elementary_test(\"test_batch_ch_in_out\", batch = 42, in_channels = 128, out_channels = 64)\n",
    "\n",
    "elementary_test(\"test_kernel_size\", kernel_size = (4,3))\n",
    "elementary_test(\"test_img_size\", img_size = (233,239))\n",
    "elementary_test(\"test_padding\", padding = (33,22))\n",
    "elementary_test(\"test_stride\", stride = (2,3))\n",
    "elementary_test(\"test_all\", batch = 42, in_channels = 64, out_channels = 128, kernel_size = (4,3), \n",
    "               img_size = (233,239), padding = (33,22), stride = (2,3))\n",
    "\n",
    "elementary_test(\"test_dilation\", dilation = (3,2))\n",
    "elementary_test(\"test_all_dilation\", batch = 42, in_channels = 64, out_channels = 128, kernel_size = (4,3), \n",
    "                img_size = (233,239), padding = (33,22), stride = (2,3), dilation = (3,2))\n",
    "\n",
    "elementary_test(\"test_groups\", in_channels = 64, out_channels = 64, groups = 64)\n",
    "elementary_test(\"test_all_groups\", batch = 42, in_channels = 64, out_channels = 128, kernel_size = (4,3), \n",
    "                img_size = (233,239), padding = (33,22), stride = (2,3), dilation = (3,2), groups = 64)\n",
    "#elementary_test(\"test_bias\", batch = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 64\n",
    "in_channels = 64\n",
    "out_channels = 64\n",
    "stride = (1,1)\n",
    "padding = (0,0)\n",
    "dilation = (4,3)\n",
    "kernel_size = (4,3)\n",
    "img_size = (108,64)\n",
    "bias = False\n",
    "groups = 1\n",
    "    \n",
    "\n",
    "m = torch.nn.Conv2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "n = Dcls2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "o = Dcls2d_old(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "Y = torch.nn.Parameter(torch.randn((batch,in_channels,*img_size),device=cuda_device))\n",
    "o.weight = n.weight = m.weight = torch.nn.Parameter(torch.ones((out_channels,in_channels//groups,*kernel_size),device=cuda_device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward: 4671.597 us | Backward 15256.667 us\n"
     ]
    }
   ],
   "source": [
    "forward = 0\n",
    "backward = 0\n",
    "for _ in range(10):\n",
    "    start = time.time()\n",
    "    a = m(Y)\n",
    "    torch.cuda.synchronize()\n",
    "    forward += time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    (a.sum()).backward()\n",
    "    torch.cuda.synchronize()\n",
    "    backward += time.time() - start\n",
    "\n",
    "print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e1, backward * 1e6/1e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward: 1057759.881 us | Backward 1107277.656 us\n"
     ]
    }
   ],
   "source": [
    "forward = 0\n",
    "backward = 0\n",
    "for _ in range(10):\n",
    "    start = time.time()\n",
    "    b = n(Y)\n",
    "    torch.cuda.synchronize()\n",
    "    forward += time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    (b.sum() ).backward()\n",
    "    torch.cuda.synchronize()\n",
    "    backward += time.time() - start\n",
    "\n",
    "print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e1, backward * 1e6/1e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward: 16189.647 us | Backward 233241.177 us\n"
     ]
    }
   ],
   "source": [
    "forward = 0\n",
    "backward = 0\n",
    "for _ in range(10):\n",
    "    start = time.time()\n",
    "    c = o(Y)\n",
    "    torch.cuda.synchronize()\n",
    "    forward += time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    (c.sum() ).backward()\n",
    "    torch.cuda.synchronize()\n",
    "    backward += time.time() - start\n",
    "\n",
    "print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e1, backward * 1e6/1e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
