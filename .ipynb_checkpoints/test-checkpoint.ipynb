{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from termcolor import colored\n",
    "import torch\n",
    "\n",
    "from modules.Dcls2d import Dcls2d\n",
    "from modules.Dcls2d_old import Dcls2d_old\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "cuda_device = torch.device(\"cuda\")  # device object representing GPU\n",
    "\n",
    "in_channels = 2\n",
    "out_channels = 2\n",
    "kernel_size = (3,3)\n",
    "dilation = (1,1)\n",
    "stride = (1,1)\n",
    "padding = (0,0)\n",
    "groups = 2\n",
    "bias = False\n",
    "\n",
    "m = torch.nn.Conv2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "n = Dcls2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "X = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3., 4., 5.],\n",
    "                                    [6., 7., 8., 9., 10.], \n",
    "                                    [11., 12., 13., 14., 15.],\n",
    "                                    [16., 17., 18., 19., 20.],                                   \n",
    "                                    [21., 22., 23., 24., 25.]],\n",
    "                                    [[1., 2., 3., 4., 5.],\n",
    "                                    [6., 7., 8., 9., 10.], \n",
    "                                    [11., 12., 13., 14., 15.],\n",
    "                                    [16., 17., 18., 19., 20.],                                   \n",
    "                                    [21., 22., 23., 24., 25.]]]],device=cuda_device),\n",
    "                      requires_grad = True) \n",
    "n.weight = m.weight = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3.],\n",
    "                                    [4., 5., 6.], \n",
    "                                    [7., 8., 9.]]],\n",
    "                                    [[[1., 2., 3.],\n",
    "                                    [4., 5., 6.], \n",
    "                                    [7., 8., 9.]]]],device=cuda_device),\n",
    "                      requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 5, 5])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([2, 2, 3, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=2, weight of size [2, 2, 3, 3], expected input[1, 2, 5, 5] to have 4 channels, but got 2 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c9d24fbec338>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 419\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=2, weight of size [2, 2, 3, 3], expected input[1, 2, 5, 5] to have 4 channels, but got 2 channels instead"
     ]
    }
   ],
   "source": [
    "print(X.size())\n",
    "print(m.weight.size())\n",
    "print(n.weight.size())\n",
    "\n",
    "print(m(X).size())\n",
    "print(m(X))\n",
    "print(n(X).size())\n",
    "print(n(X))\n",
    "\n",
    "print(n.P1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elementary_test(test_name = \"test_elem\", print_tensors = False,\n",
    "                    random_weights = True , batch = 1,\n",
    "                    in_channels = 1, out_channels = 1, \n",
    "                    stride = (1,1), padding = (0,0), \n",
    "                    dilation = (1,1), kernel_size = (3,3), \n",
    "                    img_size = (8,7), bias = None, \n",
    "                    groups = 1):\n",
    "    \n",
    "    print(\"\\n\"+ test_name + \"\\n--------------------------\")\n",
    "\n",
    "    m = torch.nn.Conv2d(in_channels=in_channels,\n",
    "                  out_channels=out_channels,\n",
    "                  kernel_size=kernel_size,\n",
    "                  dilation=dilation,\n",
    "                  stride=stride,\n",
    "                  padding=padding,\n",
    "                  groups=groups,\n",
    "                  bias=bias).to(cuda_device)\n",
    "\n",
    "    n = Dcls2d(in_channels=in_channels,\n",
    "                  out_channels=out_channels,\n",
    "                  kernel_size=kernel_size,\n",
    "                  dilation=dilation,\n",
    "                  stride=stride,\n",
    "                  padding=padding,\n",
    "                  groups=groups,\n",
    "                  bias=bias).to(cuda_device)\n",
    "\n",
    "    o = Dcls2d_old(in_channels=in_channels,\n",
    "                  out_channels=out_channels,\n",
    "                  kernel_size=kernel_size,\n",
    "                  dilation=dilation,\n",
    "                  stride=stride,\n",
    "                  padding=padding,\n",
    "                  groups=groups,\n",
    "                  bias=bias).to(cuda_device)\n",
    "\n",
    "    Y1 = torch.nn.Parameter(torch.randn((batch,in_channels,*img_size),device=cuda_device), requires_grad = True)\n",
    "    Y2 = torch.nn.Parameter(torch.randn((batch,in_channels,*img_size),device=cuda_device), requires_grad = True)\n",
    "    Y3 = torch.nn.Parameter(torch.randn((batch,in_channels,*img_size),device=cuda_device), requires_grad = True)    \n",
    "    Y3.data = Y2.data = Y1.data\n",
    "    W = torch.nn.Parameter(torch.randn((out_channels,in_channels//groups,*kernel_size),device=cuda_device), requires_grad = True)\n",
    "    B = torch.nn.Parameter(torch.randn((out_channels),device=cuda_device), requires_grad = True)\n",
    "    #o.weight = torch.nn.Parameter(torch.randn((out_channels,in_channels//groups,*kernel_size),device=cuda_device), requires_grad = True)\n",
    "    n.weight = torch.nn.Parameter(torch.randn((out_channels,in_channels//groups,*kernel_size),device=cuda_device), requires_grad = True)\n",
    "    m.weight = torch.nn.Parameter(torch.randn((out_channels,in_channels//groups,*kernel_size),device=cuda_device), requires_grad = True)\n",
    "    m.bias = torch.nn.Parameter(torch.randn((out_channels),device=cuda_device))\n",
    "    n.bias = torch.nn.Parameter(torch.randn((out_channels),device=cuda_device))\n",
    "    #o.bias = torch.nn.Parameter(torch.randn((out_channels),device=cuda_device))\n",
    "\n",
    "    \n",
    "    m.weight.data = W.data\n",
    "    n.weight.data = W.data\n",
    "    #o.weight.data = W.data\n",
    "    \n",
    "    \n",
    "    m.bias.data = B.data\n",
    "    n.bias.data = B.data\n",
    "    #o.bias.data = B.data\n",
    "    \n",
    "    height_out = (img_size[0] + 2 * padding[0] - (dilation[0] * (kernel_size[0] - 1) + 1)) / stride[0] + 1;\n",
    "    width_out = (img_size[1] + 2 * padding[1] - (dilation[1] * (kernel_size[1] - 1) + 1)) / stride[1] + 1;\n",
    "    back_truth = torch.randn((batch,out_channels,int(height_out),int(width_out)),device=cuda_device)\n",
    "    \n",
    "\n",
    "    print(\"#Forward check\")\n",
    "    \n",
    "    if (print_tensors):\n",
    "        print(m(Y1))\n",
    "        print(n(Y2))\n",
    "\n",
    "    print(colored('True', 'green')) if torch.all(torch.abs(m(Y1) - n(Y2))/torch.abs(m(Y1)) < 1e-1) else print(colored('False', 'red'))\n",
    "    #print(colored('True', 'green')) if torch.all(torch.abs(m(Y1) - o(Y3)) < 1e-2) else print(colored('False', 'red'))\n",
    "   \n",
    "    print(\"#Backward check\")\n",
    "\n",
    "    var1 = (m(Y1) - back_truth).norm()\n",
    "    var2 = (n(Y2) - back_truth).norm()\n",
    "    #var3 = (o(Y) - backtruth).norm()\n",
    "    var1.backward();\n",
    "    var2.backward();\n",
    "    #var3.backward();\n",
    "\n",
    "    if (print_tensors):\n",
    "        print(m.weight.grad)\n",
    "        print(n.weight.grad)\n",
    "        #print(o.weight)\n",
    "\n",
    "    print(colored('True', 'green')) if torch.all(torch.abs(m.weight.grad - n.weight.grad)/torch.abs(m.weight.grad) < 1e-2) else print(colored('False', 'red'))\n",
    "    print(colored('True', 'green')) if torch.all(torch.abs(Y1.grad - Y2.grad)/torch.abs(Y1.grad) < 1e-2) else print(colored('False', 'red')    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test_dil\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_dil\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_dil\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_dil\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_batch\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_ch_in\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_ch_out\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_batch_ch_in_out\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_kernel_size\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_img_size\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_padding\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[32mTrue\u001b[0m\n",
      "\n",
      "test_stride\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_all\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_dilation\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[32mTrue\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_all_dilation\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_groups\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\n",
      "test_all_groups\n",
      "--------------------------\n",
      "#Forward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "#Backward check\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "elementary_test(\"test_dil\", dilation = (6,5), kernel_size = (3,3), img_size=(32,20))\n",
    "elementary_test(\"test_dil\", dilation = (5,6), kernel_size = (3,3), img_size=(40,50))\n",
    "elementary_test(\"test_dil\", dilation = (6,6), kernel_size = (3,3), img_size=(49,56))\n",
    "elementary_test(\"test_dil\", dilation = (5,5), kernel_size = (3,3), img_size=(120,57))\n",
    "\n",
    "elementary_test(\"test_batch\", batch = 42)\n",
    "elementary_test(\"test_ch_in\", in_channels = 64, img_size = (100,100))\n",
    "elementary_test(\"test_ch_out\", out_channels = 128, print_tensors = False)\n",
    "elementary_test(\"test_batch_ch_in_out\", batch = 42, in_channels = 128,  out_channels = 64)\n",
    "\n",
    "elementary_test(\"test_kernel_size\", kernel_size = (4,3))\n",
    "elementary_test(\"test_img_size\", img_size = (233,239))\n",
    "elementary_test(\"test_padding\", padding = (33,22))\n",
    "elementary_test(\"test_stride\", stride = (2,3))\n",
    "elementary_test(\"test_all\", batch = 42, in_channels = 64, out_channels = 128, kernel_size = (4,3), \n",
    "               img_size = (233,239), padding = (33,22), stride = (2,3))\n",
    "\n",
    "elementary_test(\"test_dilation\", dilation = (3,2))\n",
    "elementary_test(\"test_all_dilation\", batch = 42, in_channels = 64, out_channels = 128, kernel_size = (4,3), \n",
    "                img_size = (233,239), padding = (33,22), stride = (2,3), dilation = (3,2))\n",
    "\n",
    "elementary_test(\"test_groups\", in_channels = 64, out_channels = 64, groups = 64)\n",
    "elementary_test(\"test_all_groups\", batch = 42, in_channels = 64, out_channels = 128, kernel_size = (4,3), \n",
    "                img_size = (233,239), padding = (33,22), stride = (2,3), dilation = (3,2), groups = 64)\n",
    "#elementary_test(\"test_bias\", batch = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 64\n",
    "in_channels = 64\n",
    "out_channels = 64\n",
    "stride = (1,1)\n",
    "padding = (0,0)\n",
    "dilation = (4,3)\n",
    "kernel_size = (4,3)\n",
    "img_size = (108,64)\n",
    "bias = False\n",
    "groups = 1\n",
    "    \n",
    "\n",
    "m = torch.nn.Conv2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "n = Dcls2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "o = Dcls2d_old(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "Y = torch.nn.Parameter(torch.randn((batch,in_channels,*img_size),device=cuda_device))\n",
    "o.weight = n.weight = m.weight = torch.nn.Parameter(torch.ones((out_channels,in_channels//groups,*kernel_size),device=cuda_device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward: 4651.856 us | Backward 15151.548 us\n"
     ]
    }
   ],
   "source": [
    "forward = 0\n",
    "backward = 0\n",
    "for _ in range(10):\n",
    "    start = time.time()\n",
    "    a = m(Y)\n",
    "    torch.cuda.synchronize()\n",
    "    forward += time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    (a.sum()).backward()\n",
    "    torch.cuda.synchronize()\n",
    "    backward += time.time() - start\n",
    "\n",
    "print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e1, backward * 1e6/1e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward: 29433.203 us | Backward 24368.739 us\n"
     ]
    }
   ],
   "source": [
    "forward = 0\n",
    "backward = 0\n",
    "for _ in range(10):\n",
    "    start = time.time()\n",
    "    b = n(Y)\n",
    "    torch.cuda.synchronize()\n",
    "    forward += time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    (b.sum() ).backward()\n",
    "    torch.cuda.synchronize()\n",
    "    backward += time.time() - start\n",
    "\n",
    "print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e1, backward * 1e6/1e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward: 18461.061 us | Backward 232120.943 us\n"
     ]
    }
   ],
   "source": [
    "forward = 0\n",
    "backward = 0\n",
    "for _ in range(10):\n",
    "    start = time.time()\n",
    "    c = o(Y)\n",
    "    torch.cuda.synchronize()\n",
    "    forward += time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    (c.sum() ).backward()\n",
    "    torch.cuda.synchronize()\n",
    "    backward += time.time() - start\n",
    "\n",
    "print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e1, backward * 1e6/1e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
