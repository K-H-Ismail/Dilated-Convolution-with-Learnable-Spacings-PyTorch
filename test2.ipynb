{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 7.6718, 11.5944],\n",
      "          [23.3621, 27.2847]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from termcolor import colored\n",
    "import torch\n",
    "\n",
    "from modules.Dcls2d import Dcls2d\n",
    "from modules.Dcls2d_old import Dcls2d_old\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "cuda_device = torch.device(\"cuda\")  # device object representing GPU\n",
    "\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "kernel_size = (2,2)\n",
    "dilation = (2,2)\n",
    "stride = (1,1)\n",
    "padding = (0,0)\n",
    "groups = 1\n",
    "bias = False\n",
    "\n",
    "m = torch.nn.Conv2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "n = Dcls2d(in_channels=in_channels,\n",
    "              out_channels=out_channels,\n",
    "              kernel_size=kernel_size,\n",
    "              dilation=dilation,\n",
    "              stride=stride,\n",
    "              padding=padding,\n",
    "              groups=groups,\n",
    "              bias=bias).to(cuda_device)\n",
    "\n",
    "X1 = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3., 4.],\n",
    "                                    [5., 6., 7., 8.], \n",
    "                                    [9., 10., 11., 12.],\n",
    "                                    [13., 14., 15., 16.]]]],device=cuda_device),\n",
    "                      requires_grad = True) \n",
    "X2 = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2., 3., 4.],\n",
    "                                    [5., 6., 7., 8.], \n",
    "                                    [9., 10., 11., 12.],\n",
    "                                    [13., 14., 15., 16.]]]],device=cuda_device),\n",
    "                      requires_grad = True) \n",
    "m.weight = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[20., 40.],\n",
    "                                    [60., 80.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "n.weight = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[20., 40.],\n",
    "                                    [60., 80.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "\n",
    "height_out = (4 + 2 * padding[0] - (dilation[0] * (kernel_size[0] - 1) + 1)) / stride[0] + 1;\n",
    "width_out = (4 + 2 * padding[1] - (dilation[1] * (kernel_size[1] - 1) + 1)) / stride[1] + 1;\n",
    "back_truth = torch.nn.Parameter(\n",
    "                      torch.tensor([[[[1., 2.],\n",
    "                                    [4., 5.]]]],device=cuda_device),\n",
    "                      requires_grad = True)\n",
    "\n",
    "var1 = (m(X1) - back_truth).norm()\n",
    "var2 = (n(X2) - back_truth).norm()\n",
    "#var3 = (o(Y) - backtruth).norm()\n",
    "\n",
    "\n",
    "var1.backward();\n",
    "print(m.weight.grad)\n",
    "var2.backward();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 4])\n",
      "torch.Size([1, 1, 2, 2])\n",
      "torch.Size([1, 1, 2, 2])\n",
      "torch.Size([1, 1, 2, 2])\n",
      "tensor([[[[1560., 1760.],\n",
      "          [2360., 2560.]]]], device='cuda:0',\n",
      "       grad_fn=<CudnnConvolutionBackward>)\n",
      "torch.Size([1, 1, 2, 2])\n",
      "tensor([[[[1559.9686, 1759.9686],\n",
      "          [2359.9688, 2559.9688]]]], device='cuda:0',\n",
      "       grad_fn=<SurrogateDilationBackward>)\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.]]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.]]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.]]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.]]], device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(m.weight.grad) \\nprint(n.weight.grad)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X1.size())\n",
    "print(m.weight.size())\n",
    "print(n.weight.size())\n",
    "\n",
    "print(m(X1).size())\n",
    "print(m(X1))\n",
    "print(n(X2).size())\n",
    "print(n(X2))\n",
    "\n",
    "R1 = torch.ceil(n.P1) - n.P1\n",
    "R2 = torch.ceil(n.P2) - n.P2\n",
    "\n",
    "print((1 - R1) * (1-R2))\n",
    "print((R1) * (1-R2))\n",
    "print((1 - R1) * (R2))\n",
    "print((R1) * (R2))\n",
    "'''print(m.weight.grad) \n",
    "print(n.weight.grad)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-2., -2.],\n",
      "         [ 0.,  0.]]], device='cuda:0', requires_grad=True)\n",
      "tensor([[[0., 0.],\n",
      "         [2., 2.]]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(n.P1)\n",
    "print(torch.ceil(n.P1) + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "def hevi(x):\n",
    "    return 1.0 if x > 0 else 0.0\n",
    "def surr_ceil(x,bot,top):\n",
    "    s = 0.0\n",
    "    \n",
    "    for i in range(1-bot,top):\n",
    "        s = s + hevi(x+i)\n",
    "    return s - top + 1\n",
    "\n",
    "\n",
    "def surr_floor(x,bot,top):\n",
    "    s = 0.0\n",
    "    \n",
    "    for i in range(-bot,top-1):\n",
    "        s = s + hevi(x+i)\n",
    "    return s - bot +1\n",
    "\n",
    "print(surr_ceil(3,5,5))\n",
    "print(surr_floor(3.1,5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1770"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "(np.array([12,24,36,48,3,6,9,12,4,8,12,16,1,2,3,4]) * np.array([1,3,9,11,5,7,13,15,2,4,10,12,6,8,14,16])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
